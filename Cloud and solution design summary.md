# GovTech-DE-Test

I would use AWS EC2 instances to deploy my code, using linux virtual environment to create and access the instance using SSH. EC2 provides more control over the environment for data processing tasks. I would put the json and excel files into a database which can be accessed through EC2 instance. This would be useful especially as EC2 provides scalability to data, i.e. if data increases in volume, you can increase the number of nodes to assist in computation. I would also use Hadoop MapReduce function if needed for batch-processing if the input data volume increases.

I chose to design my solution using object-oriented programming in python as it makes the solutions more scalable. For example, if additional design process needs to be added, I can easily create a new function in the class to do so. I can also debug any function or modify the functions easily with OOP, as the modifications in my code will be targeted to that specific function. My solutions are all also efficient with O(n) time complexity and O(n) space complexity as I only iterate through the json file once to create the dataframes required to ensure efficiency. I changed the Country-Codes to a dictionary for faster accessing as dictionary accessing is O(1), comparing to iterating through to get the country every time. I also ensured that the end resulting csv files had all the variables in a proper format, for example, an ID should be an integer not a float.

